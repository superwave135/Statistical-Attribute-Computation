{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning - Practicum 01 ‚Äì Statistical Attribute Computation\n",
    "\n",
    "**Topics covered: Calculating Descriptive Statistics**\n",
    "\n",
    "See Jupyter Notebook: ‚Äúdescriptive_statistics.ipynb‚Äù.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Your tasks [total 50 points]:**\n",
    "- Use the 13th (LSTAT: % lower status of the population) and 14th (MEDV: Median value of owner-occupied homes in $1000's) columns of the Boston house price dataset to calculate the following statistical attributes by programming with Python using pure Python or packages:\n",
    "- Note: you can download the dataset from:\n",
    "  https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
    "\n",
    "\n",
    "**[I] (18 points) Measures of Central Tendency**\n",
    "1. Mean\n",
    "2. Weighted mean\n",
    "3. Harmonic mean\n",
    "4. Geometric mean\n",
    "5. Median\n",
    "6. Mode\n",
    "\n",
    "\n",
    "**[II] (15 points) Measures of Variability**\n",
    "1. Variance\n",
    "2. Standard deviation\n",
    "3. Skewness\n",
    "4. Percentiles\n",
    "5. Ranges\n",
    "\n",
    "\n",
    "**[III] (5 points) Summary of Descriptive Statistics**\n",
    "1. Nobs: the number of observations or elements in your dataset\n",
    "2. Minmax: the tuple with the minimum and maximum values of your dataset\n",
    "3. Mean: the mean of your dataset\n",
    "4. Variance: the variance of your dataset\n",
    "5. Skewness: the skewness of your dataset\n",
    "6. Kurtosis: the kurtosis of your dataset\n",
    "\n",
    "\n",
    "**[IV] (12 points) Measures of Correlation Between Pairs of Data**\n",
    "1. Covariance\n",
    "2. Correlation Coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_cols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'] # retrieved from housing.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"housing.data\", names = name_cols, header=None, delim_whitespace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw[['LSTAT', 'MEDV']] # create a dataframe with columns LSTAT and MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTAT    0\n",
       "MEDV     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()  # check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 506\n",
      "Number of columns: 2\n"
     ]
    }
   ],
   "source": [
    "row_num = df.shape[0]\n",
    "col_num = df.shape[1]\n",
    "print(f'Number of rows: {row_num}')\n",
    "print(f'Number of columns: {col_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_LSTAT = df['LSTAT'].to_numpy()  # create numpy array for LSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_MEDV = df['MEDV'].to_numpy()  # create numpy array for MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [I] Measures of Central Tendency\n",
    "The measures of central tendency show the central or middle values of datasets. There are several definitions of what‚Äôs considered to be the center of a dataset. In this tutorial, you‚Äôll learn how to identify and calculate these measures of central tendency:\n",
    "\n",
    "(1) Mean<br>\n",
    "(2) Weighted mean<br>\n",
    "(3) Harmonic mean<br>\n",
    "(4) Geometric mean<br>\n",
    "(5) Median<br>\n",
    "(6) Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (I-1) Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of LSTAT is 12.65306324110672\n"
     ]
    }
   ],
   "source": [
    "mean_LSTAT = statistics.mean(arr_LSTAT) # alternative to np.mean(array_LSTAT)\n",
    "print(f'The mean of LSTAT is {mean_LSTAT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of MEDV is 22.532806324110673\n"
     ]
    }
   ],
   "source": [
    "mean_MEDV = statistics.mean(arr_MEDV) # alternative to np.mean(array_NEDV)\n",
    "print(f'The mean of MEDV is {mean_MEDV}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (I-2) Weighted Mean\n",
    "\n",
    "The weighted mean, also called the weighted arithmetic mean or weighted average, is a generalization of the arithmetic mean that enables you to define the relative contribution of each data point to the result.\n",
    "\n",
    "You define one weight ùë§·µ¢ for each data point ùë•·µ¢ of the dataset ùë•, where ùëñ = 1, 2, ‚Ä¶, ùëõ and ùëõ is the number of items in ùë•. Then, you multiply each data point with the corresponding weight, sum all the products, and divide the obtained sum with the sum of weights: Œ£·µ¢(ùë§·µ¢ùë•·µ¢) / Œ£·µ¢ùë§·µ¢.\n",
    "\n",
    "The weighted mean is very handy when you need the mean of a dataset containing items that occur with given relative frequencies. For example, say that you have a set in which 20% of all items are equal to 2, 50% of the items are equal to 4, and the remaining 30% of the items are equal to 8. You can calculate the mean of such a set like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean of LSTAT: 12.653063241106722\n"
     ]
    }
   ],
   "source": [
    "# calculates the weighted mean of LSTAT\n",
    "\n",
    "# importing the collections module\n",
    "import collections\n",
    "\n",
    "# getting the elements frequencies using Counter class\n",
    "elements_count = collections.Counter(arr_LSTAT)\n",
    "weighted_sum = 0\n",
    "freq = 0\n",
    "\n",
    "for key, value in elements_count.items():\n",
    "    weighted_sum += key*value\n",
    "    freq += value\n",
    "weighted_sum\n",
    "freq\n",
    "\n",
    "weighted_mean = weighted_sum/freq\n",
    "print('Weighted Mean of LSTAT:', weighted_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean of MEDV: 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "# calculates the weighted mean of MEDV\n",
    "\n",
    "# importing the collections module\n",
    "import collections\n",
    "\n",
    "# getting the elements frequencies using Counter class\n",
    "elements_count = collections.Counter(arr_MEDV)\n",
    "weighted_sum = 0\n",
    "freq = 0\n",
    "\n",
    "for key, value in elements_count.items():\n",
    "    weighted_sum += key*value\n",
    "    freq += value\n",
    "weighted_sum\n",
    "freq\n",
    "\n",
    "weighted_mean_MEDV = weighted_sum/freq\n",
    "print('Weighted Mean of MEDV:', weighted_mean_MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean of LSTAT: 12.653063241106722\n"
     ]
    }
   ],
   "source": [
    "y = np.array(arr_LSTAT)\n",
    "wmean_LSTAT = np.average(arr_LSTAT)\n",
    "wmean_LSTAT\n",
    "print('Weighted Mean of LSTAT:', wmean_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean of MEDV: 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "wmean_MEDV = np.average(arr_MEDV)\n",
    "wmean_MEDV\n",
    "print('Weighted Mean of MEDV:', wmean_MEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (I-3) Harmonic Mean\n",
    "\n",
    "The harmonic mean is the reciprocal of the mean of the reciprocals of all items in the dataset: ùëõ / Œ£·µ¢(1/ùë•·µ¢), where ùëñ = 1, 2, ‚Ä¶, ùëõ and ùëõ is the number of items in the dataset ùë•. One variant of the pure Python implementation of the harmonic mean is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic Mean LSTAT: 8.865729748193846\n"
     ]
    }
   ],
   "source": [
    "hmean_LSTAT = len(arr_LSTAT) / sum(1 / item for item in arr_LSTAT)\n",
    "hmean_LSTAT\n",
    "print('Harmonic Mean LSTAT:', hmean_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic Mean MEDV: 19.03842825084396\n"
     ]
    }
   ],
   "source": [
    "hmean_MEDV = len(arr_MEDV) / sum(1 / item for item in arr_MEDV)\n",
    "hmean_MEDV\n",
    "print('Harmonic Mean MEDV:', hmean_MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic Mean LSTAT: 8.865729748193846\n"
     ]
    }
   ],
   "source": [
    "hmean = statistics.harmonic_mean(arr_LSTAT)\n",
    "hmean_LSTAT\n",
    "print('Harmonic Mean LSTAT:', hmean_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic Mean MEDV: 19.03842825084396\n"
     ]
    }
   ],
   "source": [
    "hmean = statistics.harmonic_mean(arr_MEDV)\n",
    "hmean_MEDV\n",
    "print('Harmonic Mean MEDV:', hmean_MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic Mean LSTAT: 8.865729748193845\n"
     ]
    }
   ],
   "source": [
    "scipy.stats.hmean(arr_LSTAT)\n",
    "print('Harmonic Mean LSTAT:', scipy.stats.hmean(arr_LSTAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic Mean MEDV: 19.038428250843946\n"
     ]
    }
   ],
   "source": [
    "print('Harmonic Mean MEDV:', scipy.stats.hmean(arr_MEDV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (I-4) Geometric Mean\n",
    "\n",
    "The geometric mean is the ùëõ-th root of the product of all ùëõ elements ùë•·µ¢ in a dataset ùë•: ‚Åø‚àö(Œ†·µ¢ùë•·µ¢), where ùëñ = 1, 2, ‚Ä¶, ùëõ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can implement the geometric mean in pure Python like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the geometric mean with scipy.stats.gmean():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometric Mean of LSTAT: 10.707722037003153\n"
     ]
    }
   ],
   "source": [
    "print('Geometric Mean of LSTAT:', scipy.stats.gmean(arr_LSTAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometric Mean of MEDV: 20.7908476784859\n"
     ]
    }
   ],
   "source": [
    "print('Geometric Mean of MEDV:', scipy.stats.gmean(arr_MEDV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You obtained the same result as with the pure Python implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (I-5) Median\n",
    "\n",
    "The sample median is the middle element of a sorted dataset. The dataset can be sorted in increasing or decreasing order. If the number of elements ùëõ of the dataset is odd, then the median is the value at the middle position: 0.5(ùëõ + 1). If ùëõ is even, then the median is the arithmetic mean of the two values in the middle, that is, the items at the positions 0.5ùëõ and 0.5ùëõ + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of LSTAT: 11.36\n"
     ]
    }
   ],
   "source": [
    "print('Median of LSTAT:', statistics.median(arr_LSTAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of MEDV: 21.2\n"
     ]
    }
   ],
   "source": [
    "print('Median of MEDV:', statistics.median(arr_MEDV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You‚Äôve obtained the same values with statistics.median() and np.median()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (I-6) Mode\n",
    "\n",
    "The sample mode is the value in the dataset that occurs most frequently. If there isn‚Äôt a single such value, then the set is multimodal since it has multiple modal values. For example, in the set that contains the points 2, 3, 2, 8, and 12, the number 2 is the mode because it occurs twice, unlike the other items that occur only once.\n",
    "\n",
    "This is how you can get the mode with pure Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Series objects have the method .mode() that handles multimodal values well and ignores nan values by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode for LSTAT:\n",
      "\n",
      "0     6.36\n",
      "1     7.79\n",
      "2     8.05\n",
      "3    14.10\n",
      "4    18.13\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Mode for LSTAT:')\n",
    "print()\n",
    "print(df['LSTAT'].mode()) # There are 5 modes for LSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode of MEDV:\n",
      "\n",
      "0    50.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Mode of MEDV:') \n",
    "print()\n",
    "print(df['MEDV'].mode()) # Mode is 50 for MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [II] Measures of Variability\n",
    "\n",
    "The measures of central tendency aren‚Äôt sufficient to describe data. You‚Äôll also need the measures of variability that quantify the spread of data points. In this section, you‚Äôll learn how to identify and calculate the following variability measures:\n",
    "\n",
    "(1) Variance<br>\n",
    "(2) Standard deviation<br>\n",
    "(3) Skewness<br>\n",
    "(4) Percentiles<br>\n",
    "(5) Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (II-1) Variance\n",
    "\n",
    "The sample variance quantifies the spread of the data. It shows numerically how far the data points are from the mean. You can express the sample variance of the dataset ùë• with ùëõ elements mathematically as ùë†¬≤ = Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≤ / (ùëõ ‚àí 1), where ùëñ = 1, 2, ‚Ä¶, ùëõ and mean(ùë•) is the sample mean of ùë•.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance for LSTAT: 50.99475950886393\n"
     ]
    }
   ],
   "source": [
    "var_arr_LSTAT = statistics.variance(arr_LSTAT)\n",
    "print('Variance for LSTAT:', var_arr_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance for MEDV: 84.58672359409854\n"
     ]
    }
   ],
   "source": [
    "var_arr_MEDV = statistics.variance(arr_MEDV)\n",
    "print('Variance for MEDV:', var_arr_MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance for LSTAT: 50.994759508863936\n"
     ]
    }
   ],
   "source": [
    "var_arr_LSTAT = np.var(arr_LSTAT, ddof=1)\n",
    "print('Variance for LSTAT:', var_arr_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance for MEDV: 84.58672359409856\n"
     ]
    }
   ],
   "source": [
    "var_arr_MEDV = np.var(arr_MEDV, ddof=1)\n",
    "print('Variance for MEDV:', var_arr_MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance for LSTAT: 50.994759508863936\n"
     ]
    }
   ],
   "source": [
    "var_arr_LSTAT = arr_LSTAT.var(ddof=1)\n",
    "print('Variance for LSTAT:', var_arr_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance for MEDV: 84.58672359409856\n"
     ]
    }
   ],
   "source": [
    "var_arr_MEDV = arr_MEDV.var(ddof=1)\n",
    "print('Variance for MEDV:', var_arr_MEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (II-2) Standard Deviation\n",
    "\n",
    "The sample standard deviation is another measure of data spread. It‚Äôs connected to the sample variance, as standard deviation, ùë†, is the positive square root of the sample variance. The standard deviation is often more convenient than the variance because it has the same unit as the data points. Once you get the variance, you can calculate the standard deviation with pure Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation for LSTAT: 7.141061511348571\n"
     ]
    }
   ],
   "source": [
    "std_arr_LSTAT = var_arr_LSTAT ** 0.5\n",
    "print('Standard Deviation for LSTAT:', std_arr_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation for MEDV: 9.197104087379818\n"
     ]
    }
   ],
   "source": [
    "std_arr_MEDV = var_arr_MEDV ** 0.5\n",
    "print('Standard Deviation for MEDV:', std_arr_MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation for LSTAT: 7.14106151134857\n"
     ]
    }
   ],
   "source": [
    "std_LSTAT = statistics.stdev(arr_LSTAT)\n",
    "print('Standard Deviation for LSTAT:', std_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation for MEDV: 9.197104087379817\n"
     ]
    }
   ],
   "source": [
    "std_MEDV = statistics.stdev(arr_MEDV)\n",
    "print('Standard Deviation for MEDV:', std_MEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (II-3) Skewness\n",
    "\n",
    "The sample skewness measures the asymmetry of a data sample.\n",
    "\n",
    "There are several mathematical definitions of skewness. One common expression to calculate the skewness of the dataset ùë• with ùëõ elements is (ùëõ¬≤ / ((ùëõ ‚àí 1)(ùëõ ‚àí 2))) (Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≥ / (ùëõùë†¬≥)). A simpler expression is Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≥ ùëõ / ((ùëõ ‚àí 1)(ùëõ ‚àí 2)ùë†¬≥), where ùëñ = 1, 2, ‚Ä¶, ùëõ and mean(ùë•) is the sample mean of ùë•. The skewness defined like this is called the adjusted Fisher-Pearson standardized moment coefficient.\n",
    "\n",
    "Once you‚Äôve calculated the size of your dataset n, the sample mean mean_, and the standard deviation std_, you can get the sample skewness with pure Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skewness is positive, so x has a right-side tail.\n",
    "\n",
    "You can also calculate the sample skewness with scipy.stats.skew():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of LSTAT: 0.9064600935915368\n"
     ]
    }
   ],
   "source": [
    "print('Skewness of LSTAT:', scipy.stats.skew(arr_LSTAT, bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of MEDV: 1.1080984082549072\n"
     ]
    }
   ],
   "source": [
    "print('Skewness of MEDV:', scipy.stats.skew(arr_MEDV, bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of LSTAT: 0.9064600935915367\n"
     ]
    }
   ],
   "source": [
    "skew_LSTAT = pd.Series(df['LSTAT'])\n",
    "print('Skewness of LSTAT:', skew_LSTAT.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of MEDV: 1.1080984082549072\n"
     ]
    }
   ],
   "source": [
    "skew_MEDV = pd.Series(df['MEDV'])\n",
    "print('Skewness of MEDV:', skew_MEDV.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (II-4) Percentiles\n",
    "\n",
    "The sample ùëù percentile is the element in the dataset such that ùëù% of the elements in the dataset are less than or equal to that value. Also, (100 ‚àí ùëù)% of the elements are greater than or equal to that value. If there are two such elements in the dataset, then the sample ùëù percentile is their arithmetic mean. Each dataset has three quartiles, which are the percentiles that divide the dataset into four parts:\n",
    "\n",
    "    -- The first quartile is the sample 25th percentile. It divides roughly 25% of the smallest items from the rest of the dataset.\n",
    "    -- The second quartile is the sample 50th percentile or the median. Approximately 25% of the items lie between the first and second quartiles and another 25% between the second and third quartiles.\n",
    "    -- The third quartile is the sample 75th percentile. It divides roughly 25% of the largest items from the rest of the dataset.\n",
    "    \n",
    "You can also use np.percentile() to determine any sample percentile in your dataset. For example, this is how you can find the 5th and 95th percentiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 percentile of LSTAT: 3.7075000000000005\n"
     ]
    }
   ],
   "source": [
    "print('5 percentile of LSTAT:', np.percentile(arr_LSTAT, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 percentile of LSTAT 26.8075\n"
     ]
    }
   ],
   "source": [
    "print('95 percentile of LSTAT', np.percentile(arr_LSTAT, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.95  11.36  16.955]\n",
      "25 percentile of LSTAT: 6.95\n",
      "50 percentile of LSTAT: 11.36\n",
      "75 percentile of LSTAT: 16.955\n"
     ]
    }
   ],
   "source": [
    "percentile_25_50_75_LSTAT = np.percentile(arr_LSTAT, [25, 50, 75])\n",
    "print(percentile_25_50_75_LSTAT)\n",
    "print('25 percentile of LSTAT:', round(percentile_25_50_75_LSTAT[0], 2))\n",
    "print('50 percentile of LSTAT:', round(percentile_25_50_75_LSTAT[1], 2))\n",
    "print('75 percentile of LSTAT:', round(percentile_25_50_75_LSTAT[2], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median value of LSTAT: 11.36\n"
     ]
    }
   ],
   "source": [
    "print('Median value of LSTAT:', np.median(arr_LSTAT)) # same as the 50 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 percentile of MEDV: 10.2\n"
     ]
    }
   ],
   "source": [
    "print('5 percentile of MEDV:', np.percentile(arr_MEDV, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 percentile of MEDV: 43.4\n"
     ]
    }
   ],
   "source": [
    "print('95 percentile of MEDV:', np.percentile(arr_MEDV, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.025 21.2   25.   ]\n",
      "25 percentile of MEDV: 17.02\n",
      "50 percentile of MEDV: 21.2\n",
      "75 percentile of MEDV: 25.0\n"
     ]
    }
   ],
   "source": [
    "percentile_25_50_75_MEDV = np.percentile(arr_MEDV, [25, 50, 75])\n",
    "print(percentile_25_50_75_MEDV)\n",
    "print('25 percentile of MEDV:', round(percentile_25_50_75_MEDV[0], 2))\n",
    "print('50 percentile of MEDV:', round(percentile_25_50_75_MEDV[1], 2))\n",
    "print('75 percentile of MEDV:', round(percentile_25_50_75_MEDV[2], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median value of MEDV: 21.2\n"
     ]
    }
   ],
   "source": [
    "print('Median value of MEDV:', np.median(arr_MEDV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (II-5) Ranges\n",
    "\n",
    "The range of data is the difference between the maximum and minimum element in the dataset. You can get it with the function np.ptp():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of LSTAT: 36.24\n"
     ]
    }
   ],
   "source": [
    "print('Range of LSTAT:', np.ptp(arr_LSTAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of MEDV: 45.0\n"
     ]
    }
   ],
   "source": [
    "print('Range of MEDV:', np.ptp(arr_MEDV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns nan if there are nan values in your NumPy array. If you use a Pandas Series object, then it will return a number.\n",
    "\n",
    "Alternatively, you can use built-in Python, NumPy, or Pandas functions and methods to calculate the maxima and minima of sequences:\n",
    "\n",
    "    -- max() and min() from the Python standard library\n",
    "    -- amax() and amin() from NumPy\n",
    "    -- nanmax() and nanmin() from NumPy to ignore nan values\n",
    "    -- .max() and .min() from NumPy\n",
    "    -- .max() and .min() from Pandas to ignore nan values by default\n",
    "\n",
    "Here are some examples of how you would use these routines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of LSTAT: 36.24\n"
     ]
    }
   ],
   "source": [
    "print('Range of LSTAT:', np.amax(arr_LSTAT) - np.amin(arr_LSTAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of MEDV: 45.0\n"
     ]
    }
   ],
   "source": [
    "print('Range of MEDV:', np.amax(arr_MEDV) - np.amin(arr_MEDV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of LSTAT: 36.24\n"
     ]
    }
   ],
   "source": [
    "print('Range of LSTAT:', arr_LSTAT.max() - arr_LSTAT.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of MEDV: 45.0\n"
     ]
    }
   ],
   "source": [
    "print('Range of MEDV:', arr_MEDV.max() - arr_MEDV.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That‚Äôs how you get the range of data.\n",
    "\n",
    "The interquartile range is the difference between the first and third quartile. Once you calculate the quartiles, you can take their difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTAT interquartile range between the 1st & 3rd quartile: 10.005\n"
     ]
    }
   ],
   "source": [
    "quartiles = np.quantile(arr_LSTAT, [0.25, 0.75])\n",
    "print('LSTAT interquartile range between the 1st & 3rd quartile:', round((quartiles[1] - quartiles[0]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDV interquartile range between the 1st & 3rd quartile: 7.975\n"
     ]
    }
   ],
   "source": [
    "quartiles = np.quantile(arr_MEDV, [0.25, 0.75])\n",
    "print('MEDV interquartile range between the 1st & 3rd quartile:', round((quartiles[1] - quartiles[0]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTAT interquartile range between the 1st & 3rd quartile: 10.005\n"
     ]
    }
   ],
   "source": [
    "quartiles = df['LSTAT'].quantile([0.25, 0.75])\n",
    "print('LSTAT interquartile range between the 1st & 3rd quartile:', round((quartiles[0.75] - quartiles[0.25]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDV interquartile range between the 1st & 3rd quartile: 7.975\n"
     ]
    }
   ],
   "source": [
    "quartiles = df['MEDV'].quantile([0.25, 0.75])\n",
    "print('MEDV interquartile range between the 1st & 3rd quartile:', round((quartiles[0.75] - quartiles[0.25]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [III] Summary of Descriptive Statistics\n",
    "\n",
    "SciPy and Pandas offer useful routines to quickly get descriptive statistics with a single function or method call. You can use scipy.stats.describe() like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTAT:\n",
      " DescribeResult(nobs=506, minmax=(1.73, 37.97), mean=12.653063241106722, variance=50.994759508863936, skewness=0.9064600935915368, kurtosis=0.4932395173927282)\n"
     ]
    }
   ],
   "source": [
    "result_LSTAT = scipy.stats.describe(arr_LSTAT, ddof=1, bias=False)\n",
    "print('LSTAT:\\n', result_LSTAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDV:\n",
      " DescribeResult(nobs=506, minmax=(5.0, 50.0), mean=22.532806324110677, variance=84.58672359409856, skewness=1.1080984082549072, kurtosis=1.4951969441658175)\n"
     ]
    }
   ],
   "source": [
    "result_MEDV = scipy.stats.describe(arr_MEDV, ddof=1, bias=False)\n",
    "print('MEDV:\\n', result_MEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to provide the dataset as the first argument. The argument can be a NumPy array, list, tuple, or similar data structure. You can omit ddof=1 since it‚Äôs the default and only matters when you‚Äôre calculating the variance. You can pass bias=False to force correcting the skewness and kurtosis for statistical bias.\n",
    "\n",
    "describe() returns an object that holds the following descriptive statistics:\n",
    "\n",
    "    -- nobs: the number of observations or elements in your dataset\n",
    "    -- minmax: the tuple with the minimum and maximum values of your dataset\n",
    "    -- mean: the mean of your dataset\n",
    "    -- variance: the variance of your dataset\n",
    "    -- skewness: the skewness of your dataset\n",
    "    -- kurtosis: the kurtosis of your dataset\n",
    "\n",
    "You can access particular values with dot notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in LSTAT: 506\n"
     ]
    }
   ],
   "source": [
    "print('Number of observations in LSTAT:', result_LSTAT.nobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value in LSTAT: 1.73\n"
     ]
    }
   ],
   "source": [
    "print('Min value in LSTAT:', result_LSTAT.minmax[0])  # Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value in LSTAT: 37.97\n"
     ]
    }
   ],
   "source": [
    "print('Max value in LSTAT:', result_LSTAT.minmax[1])  # Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of LSTAT: 12.653063241106722\n"
     ]
    }
   ],
   "source": [
    "print('Mean of LSTAT:', result_LSTAT.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of LSTAT: 50.994759508863936\n"
     ]
    }
   ],
   "source": [
    "print('Variance of LSTAT:', result_LSTAT.variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of LSTAT: 0.9064600935915368\n"
     ]
    }
   ],
   "source": [
    "print('Skewness of LSTAT:', result_LSTAT.skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kurtosis of LSTAT: 0.4932395173927282\n"
     ]
    }
   ],
   "source": [
    "print('Kurtosis of LSTAT:', result_LSTAT.kurtosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in MEDV: 506\n"
     ]
    }
   ],
   "source": [
    "print('Number of observations in MEDV:', result_MEDV.nobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value in MEDV: 5.0\n"
     ]
    }
   ],
   "source": [
    "print('Min value in MEDV:', result_MEDV.minmax[0])  # Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value in MEDV: 50.0\n"
     ]
    }
   ],
   "source": [
    "print('Max value in MEDV:', result_MEDV.minmax[1])  # Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of MEDV: 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "print('Mean of MEDV:', result_MEDV.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of MEDV: 84.58672359409856\n"
     ]
    }
   ],
   "source": [
    "print('Variance of MEDV:', result_MEDV.variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of MEDV: 1.1080984082549072\n"
     ]
    }
   ],
   "source": [
    "print('Skewness of MEDV:', result_MEDV.skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kurtosis of MEDV: 1.4951969441658175\n"
     ]
    }
   ],
   "source": [
    "print('Kurtosis of MEDV:', result_MEDV.kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SciPy, you‚Äôre just one function call away from a descriptive statistics summary for your dataset.\n",
    "\n",
    "Pandas has similar, if not better, functionality. Series objects have the method .describe():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns a new Series that holds the following:\n",
    "\n",
    "    -- count: the number of elements in your dataset\n",
    "    -- mean: the mean of your dataset\n",
    "    -- std: the standard deviation of your dataset\n",
    "    -- min and max: the minimum and maximum values of your dataset\n",
    "    -- 25%, 50%, and 75%: the quartiles of your dataset\n",
    "\n",
    "If you want the resulting Series object to contain other percentiles, then you should specify the value of the optional parameter percentiles. You can access each item of result with its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    506.000000\n",
       "mean      12.653063\n",
       "std        7.141062\n",
       "min        1.730000\n",
       "25%        6.950000\n",
       "50%       11.360000\n",
       "75%       16.955000\n",
       "max       37.970000\n",
       "Name: LSTAT, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTAT = df['LSTAT'].describe()\n",
    "result_LSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.653063241106722"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTAT['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.141061511348571"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTAT['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.73"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTAT['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.97"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTAT['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.949999999999999"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTAT['25%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.36"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTAT['50%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.955000000000002"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTAT['75%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    506.000000\n",
       "mean      22.532806\n",
       "std        9.197104\n",
       "min        5.000000\n",
       "25%       17.025000\n",
       "50%       21.200000\n",
       "75%       25.000000\n",
       "max       50.000000\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_MEDV = df['MEDV'].describe()\n",
    "result_MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_MEDV['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.197104087379818"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_MEDV['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_MEDV['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_MEDV['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.025"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_MEDV['25%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_MEDV['50%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_MEDV['75%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That‚Äôs how you can get descriptive statistics of a Series object with a single method call using Pandas.\n",
    "\n",
    "## [IV] Measures of Correlation Between Pairs of Data\n",
    "\n",
    "You‚Äôll often need to examine the relationship between the corresponding elements of two variables in a dataset. Say there are two variables, ùë• and ùë¶, with an equal number of elements, ùëõ. Let ùë•‚ÇÅ from ùë• correspond to ùë¶‚ÇÅ from ùë¶, ùë•‚ÇÇ from ùë• to ùë¶‚ÇÇ from ùë¶, and so on. You can then say that there are ùëõ pairs of corresponding elements: (ùë•‚ÇÅ, ùë¶‚ÇÅ), (ùë•‚ÇÇ, ùë¶‚ÇÇ), and so on.\n",
    "\n",
    "You‚Äôll see the following measures of correlation between pairs of data:\n",
    "\n",
    "    -- Positive correlation exists when larger values of ùë• correspond to larger values of ùë¶ and vice versa.\n",
    "    -- Negative correlation exists when larger values of ùë• correspond to smaller values of ùë¶ and vice versa.\n",
    "    -- Weak or no correlation exists if there is no such apparent relationship.\n",
    "    \n",
    "The two statistics that measure the correlation between datasets are covariance and the correlation coefficient. Let‚Äôs define some data to work with these measures. You‚Äôll create two Python lists and use them to get corresponding NumPy arrays and Pandas Series:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IV-1) Covariance\n",
    "\n",
    "The sample covariance is a measure that quantifies the strength and direction of a relationship between a pair of variables:\n",
    "\n",
    "    -- If the correlation is positive, then the covariance is positive, as well. A stronger relationship corresponds to a higher value of the covariance.\n",
    "    -- If the correlation is negative, then the covariance is negative, as well. A stronger relationship corresponds to a lower (or higher absolute) value of the covariance.\n",
    "    -- If the correlation is weak, then the covariance is close to zero.\n",
    "\n",
    "The covariance of the variables ùë• and ùë¶ is mathematically defined as ùë†À£ ∏ = Œ£·µ¢ (ùë•·µ¢ ‚àí mean(ùë•)) (ùë¶·µ¢ ‚àí mean(ùë¶)) / (ùëõ ‚àí 1), where ùëñ = 1, 2, ‚Ä¶, ùëõ, mean(ùë•) is the sample mean of ùë•, and mean(ùë¶) is the sample mean of ùë¶. It follows that the covariance of two identical variables is actually the variance: ùë†À£À£ = Œ£·µ¢(ùë•·µ¢ ‚àí mean(ùë•))¬≤ / (ùëõ ‚àí 1) = (ùë†À£)¬≤ and ùë† ∏ ∏ = Œ£·µ¢(ùë¶·µ¢ ‚àí mean(ùë¶))¬≤ / (ùëõ ‚àí 1) = (ùë† ∏)¬≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you have to find the mean of x and y. Then, you apply the mathematical formula for the covariance.\n",
    "\n",
    "NumPy has the function cov() that returns the covariance matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that cov() has the optional parameters bias, which defaults to False, and ddof, which defaults to None. Their default values are suitable for getting the sample covariance matrix. The upper-left element of the covariance matrix is the covariance of x and x, or the variance of x. Similarly, the lower-right element is the covariance of y and y, or the variance of y. You can check to see that this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix of LSTAT_MEDV:\n",
      "\n",
      " [[ 50.99475951 -48.44753832]\n",
      " [-48.44753832  84.58672359]]\n"
     ]
    }
   ],
   "source": [
    "cov_matrix_LSTAT_MEDV = np.cov(arr_LSTAT, arr_MEDV)\n",
    "print('Covariance Matrix of LSTAT_MEDV:\\n\\n', cov_matrix_LSTAT_MEDV) # covariance matrix of LSTAT ad MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance of LSTAT and LSTAT: 50.994759508863936\n"
     ]
    }
   ],
   "source": [
    "print('Covariance of LSTAT and LSTAT:', arr_LSTAT.var(ddof=1)) # covariance of LSTAT and LSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance of MEDV and MEDV: 84.58672359409856\n"
     ]
    }
   ],
   "source": [
    "print('Covariance of MEDV and MEDV:', arr_MEDV.var(ddof=1)) # covariance of MEDV and MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the variances of x and y are equal to cov_matrix[0, 0] and cov_matrix[1, 1], respectively.\n",
    "\n",
    "The other two elements of the covariance matrix are equal and represent the actual covariance between x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance of LSTAT and MEDV: -48.447538316440344\n"
     ]
    }
   ],
   "source": [
    "cov_LSTAT_MEDV = cov_matrix_LSTAT_MEDV[0, 1]\n",
    "print('Covariance of LSTAT and MEDV:', cov_LSTAT_MEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You‚Äôve obtained the same value of the covariance with np.cov() as with pure Python.\n",
    "\n",
    "Pandas Series have the method .cov() that you can use to calculate the covariance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance of LSTAT and MEDV: -48.447538316440344\n"
     ]
    }
   ],
   "source": [
    "cov_xy = df['LSTAT'].cov(df['MEDV'])\n",
    "print('Covariance of LSTAT and MEDV:', cov_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance of LSTAT and MEDV: -48.447538316440344\n"
     ]
    }
   ],
   "source": [
    "cov_xy = df['MEDV'].cov(df['LSTAT'])\n",
    "print('Covariance of LSTAT and MEDV:', cov_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IV-2) Correlation Coefficient\n",
    "\n",
    "The correlation coefficient, or Pearson product-moment correlation coefficient, is denoted by the symbol ùëü. The coefficient is another measure of the correlation between data. You can think of it as a standardized covariance. Here are some important facts about it:\n",
    "\n",
    "    -- The value ùëü > 0 indicates positive correlation.\n",
    "    -- The value ùëü < 0 indicates negative correlation.\n",
    "    -- The value r = 1 is the maximum possible value of ùëü. It corresponds to a perfect positive linear relationship between variables.\n",
    "    -- The value r = ‚àí1 is the minimum possible value of ùëü. It corresponds to a perfect negative linear relationship between variables.\n",
    "    -- The value r ‚âà 0, or when ùëü is around zero, means that the correlation between variables is weak.\n",
    "\n",
    "The mathematical formula for the correlation coefficient is ùëü = ùë†À£ ∏ / (ùë†À£ùë† ∏) where ùë†À£ and ùë† ∏ are the standard deviations of ùë• and ùë¶ respectively. If you have the means (mean_x and mean_y) and standard deviations (std_x, std_y) for the datasets x and y, as well as their covariance cov_xy, then you can calculate the correlation coefficient with pure Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You‚Äôve got the variable r that represents the correlation coefficient.\n",
    "\n",
    "scipy.stats has the routine pearsonr() that calculates the correlation coefficient and the ùëù-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: -0.7376627261740147\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = scipy.stats.pearsonr(arr_LSTAT, arr_MEDV)\n",
    "print('Correlation Coefficient:', corr_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 5.081103394387547e-88\n"
     ]
    }
   ],
   "source": [
    "print('p-value:', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pearsonr() returns a tuple with two numbers. The first one is ùëü and the second is the ùëù-value.\n",
    "\n",
    "Similar to the case of the covariance matrix, you can apply np.corrcoef() with x_ and y_ as the arguments and get the correlation coefficient matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient matrix:\n",
      "\n",
      " [[ 1.         -0.73766273]\n",
      " [-0.73766273  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(arr_LSTAT, arr_MEDV)\n",
    "print('Correlation coefficient matrix:\\n\\n', corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper-left element is the correlation coefficient between x_ and x_. The lower-right element is the correlation coefficient between y_ and y_. Their values are equal to 1.0. The other two elements are equal and represent the actual correlation coefficient between x_ and y_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: -0.7376627261740147\n"
     ]
    }
   ],
   "source": [
    "corr_coef = corr_matrix[0, 1]\n",
    "print('Correlation Coefficient:', corr_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: -0.7376627261740147\n"
     ]
    }
   ],
   "source": [
    "corr_coef = corr_matrix[1, 0]\n",
    "print('Correlation Coefficient:', corr_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression results:\n",
      " LinregressResult(slope=-0.9500493537579908, intercept=34.5538408793831, rvalue=-0.737662726174015, pvalue=5.081103394387796e-88, stderr=0.03873341621263941)\n"
     ]
    }
   ],
   "source": [
    "print('Linear regression results:\\n', scipy.stats.linregress(arr_LSTAT, arr_MEDV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linregress() takes x_ and y_, performs linear regression, and returns the results. slope and intercept define the equation of the regression line, while rvalue is the correlation coefficient. To access particular values from the result of linregress(), including the correlation coefficient, use dot notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: -0.737662726174015\n"
     ]
    }
   ],
   "source": [
    "result = scipy.stats.linregress(arr_LSTAT, arr_MEDV)\n",
    "corr_coef = result.rvalue\n",
    "print('Correlation Coefficient:', corr_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That‚Äôs how you can perform linear regression and obtain the correlation coefficient.\n",
    "\n",
    "Pandas Series have the method .corr() for calculating the correlation coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: -0.7376627261740147\n"
     ]
    }
   ],
   "source": [
    "corr_coef = df['LSTAT'].corr(df['MEDV'])\n",
    "print('Correlation Coefficient:', corr_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: -0.7376627261740147\n"
     ]
    }
   ],
   "source": [
    "corr_coef = df['MEDV'].corr(df['LSTAT'])\n",
    "print('Correlation Coefficient:', corr_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should call .corr() on one Series object and pass the other object as the first argument.\n",
    "\n",
    "The end of the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
